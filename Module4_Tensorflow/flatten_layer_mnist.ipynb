{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten layer, mnist data\n",
    "\n",
    "Simple classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py4TQ5phMLwL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AbwJWSz9z0X"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuVOylTVKOp7"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['data'].shape\n",
    "mnist['data'].to_numpy().reshape(-1, 28, 28).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create training and test split, and further split the training set into assessment and validation sets. We can scale by dividing by 255, as the pixel values are 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnrfpJL-O750"
   },
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(mnist['data']/255, mnist['target'], stratify= mnist['target'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train.to_numpy().reshape((39375, 28, 28))[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSSW1MC6FhIF"
   },
   "source": [
    "## MLP models tensorflow/keras\n",
    "\n",
    "#### Use Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aksKLyW_-Ftu"
   },
   "source": [
    "#### Tensorflow mnist data\n",
    "is 28 x 28 data. The sklearn and keras versions are the same just formatted differently. We can use either and reshape as necessary. For variety we will load the tf data and reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_keras = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYZoD7Q08C25",
    "outputId": "4f4c3040-fbae-4322-9762-abea09b56320"
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = mnist_keras\n",
    "\n",
    "X_train_full = X_train_full/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With keras we have much more flexibility. But we also must correctly set the output layers and the activation on the output, to be appropriate with the loss function.\n",
    "\n",
    "`SparseCategoricalCrossentropy` is just the multiclass log likelihood- the multiclass version of logistic regression. If we use one hot on the labels (we dont need to here), we should use `CategoricalCrossentropy`. `from_logits` is set to true when there is no softmax activation on the output layer. This is all in the keras documentation.\n",
    "\n",
    "We first define the model and then we compile it. Then we fit. There are many more available parameters for `compile`. You should check them out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK_QoDJ-ACqQ"
   },
   "outputs": [],
   "source": [
    "# bla bla\n",
    "kmlp = keras.models.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "    ]\n",
    ")\n",
    "\n",
    "kmlp.compile(loss = SparseCategoricalCrossentropy(),\n",
    "              optimizer = keras.optimizers.legacy.SGD(\n",
    "                    learning_rate=0.01,            \n",
    "                    name='SGD'), \n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M13giQk93XWM"
   },
   "outputs": [],
   "source": [
    "kmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDRqIjCR2vXs",
    "outputId": "6a1d7f63-2f47-42c4-e2e6-3a9b7fab9f41"
   },
   "outputs": [],
   "source": [
    "kmlp.fit(X_train, y_train, \n",
    "         epochs = 10, \n",
    "         validation_data=(X_val, y_val), \n",
    "         verbose = True)\n",
    "\n",
    "loss_and_metrics = kmlp.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"Accuracy: {:.4f}\".format(loss_and_metrics[1]))\n",
    "print(\"Cross entropy: {:.4f}\".format(loss_and_metrics[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19ifNXs9cN5S",
    "outputId": "e14db309-4adf-4b73-a960-31a0bf2fd293"
   },
   "outputs": [],
   "source": [
    "classes = kmlp.predict(X_test, batch_size = 128)\n",
    "np.set_printoptions(precision=2)\n",
    "print(classes[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQLfLif-NK_c"
   },
   "outputs": [],
   "source": [
    "hard_preds = np.argmax(classes, axis= 1)\n",
    "#hard_preds = kmlp.predict_classes(X_test)\n",
    "print(hard_preds[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate and visualize incorrect. From Dietel and Dietel (You may have used in Python programming class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(kmlp.predict(X_test), axis= 1)\n",
    "print(np.mean(preds != y_test))\n",
    "badX = X_test[preds != y_test,:,:]\n",
    "preds_badX = np.argmax(kmlp.predict(badX), axis= 1)\n",
    "y_badX = y_test[preds != y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes =  plt.subplots(4, 6, figsize =(16, 10), subplot_kw={'xticks': (), 'yticks':()})\n",
    "\n",
    "for ax, item, bp, y in zip(axes.ravel(), badX, preds_badX, y_badX):\n",
    "    ax.imshow(item.reshape(28,28))\n",
    "    #plt.gray()\n",
    "    ax.set_title(f'pred: {bp}, true: {y}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "\n",
    "- We've done no model tuning, tolerance and max iterations were not optimally set. \n",
    "- We've used dense layers for our model. In fact, convolution networks work best with image data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "m5mFGijOFaIo"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
