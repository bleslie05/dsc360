{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable weights note\n",
    "\n",
    "Simple example to illustrate how the `trainable_weights` attribute of a keras model keeps track of the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some binary categorical random data with ten predictors. We could use numpy but let's use tensorflow. The categorical is a little verbose, but the way it works is that the first argument is the \"unnormalized logit\". This is simply the linear function of the data $X\\beta$ before softmax activation. See *Logit remarks* handout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.normal(\n",
    "    shape = [100, 4],\n",
    "    mean=0.0,\n",
    "    stddev=1.0\n",
    ")\n",
    "\n",
    "y = tf.random.categorical(np.log([[0.5, 0.5]]), 100)\n",
    "y = tf.reshape(y, (-1, 1))  # we want a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model. Here we could use softmax with two output neurons or sigmoid with one output neuron. We do the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(4, ))\n",
    "x = inputs\n",
    "x = Dense(2, activation='relu')(x)\n",
    "x = Dense(3, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the first layer will have four weights each for the two neurons, plus the two biases - one for each neuron, for ten params. The next layer has two weights for each of the three neurons, plus the three neurons, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainable_weights` is a list. Each element is an array containing weights or biases, with one array of each for each layer, in order starting from the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 6\n"
     ]
    }
   ],
   "source": [
    "print(\"length =\", len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer weights shape = (4, 2)\n",
      "first layer bias shape = (2,)\n",
      "second layer weights shape = (2, 3)\n",
      "second layer bias shape = (3,)\n",
      "etcetera...\n"
     ]
    }
   ],
   "source": [
    "print(\"first layer weights shape =\", model.trainable_weights[0].shape)\n",
    "print(\"first layer bias shape =\", model.trainable_weights[1].shape)\n",
    "\n",
    "print(\"second layer weights shape =\", model.trainable_weights[2].shape)\n",
    "print(\"second layer bias shape =\", model.trainable_weights[3].shape)\n",
    "\n",
    "print(\"etcetera...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
