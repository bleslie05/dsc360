{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data.\n",
    "\n",
    "We use the data \n",
    "\n",
    "- default\n",
    "- bikes\n",
    "\n",
    "These were used last week and are on Brightspace.\n",
    "\n",
    "We consider the categorical predictors, encoding \"manually\" and then using `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and inspect data. You will of course need to import from the appropriate directory on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv('../data/default.csv')  #You will of course need to import from the appropriate directory on your machine.\n",
    "default.head()\n",
    "default.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use `map` to encode the `student` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = default['student'].map({'Yes': 1, 'No': 0})\n",
    "dummies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice we would not keep both columns. This is just for illustration, and to leave the original column intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default['student2'] = default['student'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "default.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use a lambda function. This is overkill- just shown as illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default['student2'] = default['student'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "default.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use `get_dummies`. Note we would typically only keep one of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(default['student']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we could do this (maybe the simplest for binary data). Note that boolean `True`, `False` behave like ones and zeros- we can find the mean, add, subtract, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default['student2'] = default['student']==\"Yes\"\n",
    "\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try one hot from sklearn. It will generalize to situations where we one hot many predictors at once. We re-load the data to get a fresh copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv('../data/default.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `OneHotEncoder` has `fit`, `transform`, and `fit_transform` methods. You can guess what they do but see the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder()\n",
    "\n",
    "student_encoded = ohc.fit_transform(default[['student']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What \"attributes\" does our `ohc` encoder have? A quick way to find out is to type `ohc.` You will get a list of auto-complete options right after you type the the period. For a description, check the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a data frame- later we will not need to do this. We do it here for illustration. We use the `toarray` method to put `student_encoded` in a pandas friendly format.\n",
    "\n",
    "Note that the encoding creates two columns. Usually we will only keep one. We address this below.Note that it creates two columns. Usually we will only keep one. We address this below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = pd.DataFrame(student_encoded.toarray(), columns = ohc.get_feature_names_out())\n",
    "student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 default student      balance        income  student_Yes\n",
       "0         1.0      No      No   729.526495  44361.625074          NaN\n",
       "1         2.0      No     Yes   817.180407  12106.134700          NaN\n",
       "2         3.0      No      No  1073.549164  31767.138947          NaN\n",
       "3         4.0      No      No   529.250605  35704.493935          NaN\n",
       "4         5.0      No      No   785.655883  38463.495879          NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_enc = pd.concat([default, student_df])\n",
    "default_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicolinearity\n",
    "\n",
    "Or simply, colinearity. This happens when columns - that is, the predictors - are dependent. See ISLR/ISLP for review. For example, homework, quiz, test grades, and final average- knowing three of these determines the fourth. In this case, with student_yes and student_no, the value of one of these determines the other. Such is the case when one hot encoding categorical predictors if we generate a column for each category, or *level*. For some models this is problematic (unregularized linear regression models in particular). So we often want to drop one of the columns. K nearest neighbors and tree based methods dont care one way or the other. \n",
    "\n",
    "To drop columns and handle other options we can add arguments to `OneHotEncoder`. For example, when might unknown category be encountered? How will it be encoded? See the documentation. \n",
    "\n",
    "We can combine the encoded predictor columns with the original data using pandas `concat` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "student_encoded = ohc.fit_transform(default[['student']])\n",
    "\n",
    "student_df = pd.DataFrame(student_encoded.toarray(), columns = ohc.get_feature_names_out())\n",
    "\n",
    "default_enc = pd.concat([default, student_df] ## combine the dataframes\n",
    "\n",
    "default_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bikes data\n",
    "- categorical predictors with more levels \n",
    "- ordinal predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp_actual</th>\n",
       "      <th>temp_feel</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>weather_cat</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>winter</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Sat</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>57.399525</td>\n",
       "      <td>64.72625</td>\n",
       "      <td>80.5833</td>\n",
       "      <td>10.749882</td>\n",
       "      <td>categ2</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>winter</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Mon</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>46.491663</td>\n",
       "      <td>49.04645</td>\n",
       "      <td>43.7273</td>\n",
       "      <td>16.636703</td>\n",
       "      <td>categ1</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>winter</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Tue</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>46.760000</td>\n",
       "      <td>51.09098</td>\n",
       "      <td>59.0435</td>\n",
       "      <td>10.739832</td>\n",
       "      <td>categ1</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>winter</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Wed</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>48.749427</td>\n",
       "      <td>52.63430</td>\n",
       "      <td>43.6957</td>\n",
       "      <td>12.522300</td>\n",
       "      <td>categ1</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>winter</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Fri</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>46.503324</td>\n",
       "      <td>50.79551</td>\n",
       "      <td>49.8696</td>\n",
       "      <td>11.304642</td>\n",
       "      <td>categ2</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  season  year month day_of_week  weekend holiday  temp_actual  \\\n",
       "0  2011-01-01  winter  2011   Jan         Sat     True      no    57.399525   \n",
       "1  2011-01-03  winter  2011   Jan         Mon    False      no    46.491663   \n",
       "2  2011-01-04  winter  2011   Jan         Tue    False      no    46.760000   \n",
       "3  2011-01-05  winter  2011   Jan         Wed    False      no    48.749427   \n",
       "4  2011-01-07  winter  2011   Jan         Fri    False      no    46.503324   \n",
       "\n",
       "   temp_feel  humidity  windspeed weather_cat  rides  \n",
       "0   64.72625   80.5833  10.749882      categ2    654  \n",
       "1   49.04645   43.7273  16.636703      categ1   1229  \n",
       "2   51.09098   59.0435  10.739832      categ1   1454  \n",
       "3   52.63430   43.6957  12.522300      categ1   1518  \n",
       "4   50.79551   49.8696  11.304642      categ2   1362  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv') ### your path will depend on where you put the file.\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            object\n",
       "season          object\n",
       "year             int64\n",
       "month           object\n",
       "day_of_week     object\n",
       "weekend           bool\n",
       "holiday         object\n",
       "temp_actual    float64\n",
       "temp_feel      float64\n",
       "humidity       float64\n",
       "windspeed      float64\n",
       "weather_cat     object\n",
       "rides            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop some columns for simplicity, and focus on day of week, weekend, weather category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = bikes.drop(columns = ['date', 'season', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the `day_of_week` predictor using one hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder(drop='first', handle_unknown='error')\n",
    "week_day_enc = ohc.fit_transform(bikes[[\"day_of_week\"]])\n",
    "week_day_df = pd.DataFrame(week_day_enc.toarray(), columns = ohc.get_feature_names_out())\n",
    "week_day_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `weekend`. Notice that it is boolean. So we should be able to leave this as is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the weather_cat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But weather is actually an ordinal predictor. We will use ordinal encoder. Does it matter if we drop the first? How are the numerical values determined? can we specify? Is there a default? Check the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = OrdinalEncoder(categories=[['categ1', 'categ2', 'categ3']])\n",
    "\n",
    "weather_ord = ord.fit_transform(bikes[[\"weather_cat\"]])\n",
    "weather_df = pd.DataFrame(weather_ord, columns = ['weather_ord'])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one hot encoder maps integer values 0 to number of categories - 1, in the order you specify. The default is alphabetical order! So you should make sure your levels are in the correct order.\n",
    "\n",
    "Ordinal encoder does not support custom mappings. However, you could use the following to map your own numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom mapping as a dictionary (assumes your categories are category1 , et. )\n",
    "mapping = {'category1': 3, 'category2': 2, 'category3': 1}\n",
    "\n",
    "# Apply the mapping to your column (assumes \"column_to_encocde\" is the name of your column and df is the name of your dataframe)\n",
    "df['column_to_encode'] = df['column_to_encode'].map(mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
